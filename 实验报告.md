[TOC]

## 实验报告

### 对其它算法的综述

#### LRU的缺点

最典型的算法是LRU。LRU在什么时候效果好？在时间局部性很高的时候。有2种典型情况会使LRU的效果不好。

第一是，如果working set比cache size要大，那么缺失率显著提高。设一个access pattern是(a1,...,aT)N，N为循环次数，设cache size是K，简单起见(如果不是全相联的，那么就局限于一个set之内)，cache是全相联的，如果恰好有K=T，那么不会有任何缺失。但如果T=K+1，那么LRU的命中率就变成了0。发生了这样的事：一个块刚被替换，立马就访问，发生缺失。此为thrash。当每个块的重用间隔>cache的块大小的时候，命中率就会很低，这里举一个命中率为0的例子。假设cache只有3个块，pattern是(a1,a2,a3,a4)循环，那么此时的命中率就是0。

第二是，进入cache的实际上再也不会被引用到。这样，这些用不到的的确会逐渐被驱逐出去，但需要缺失很多次才会把这样的一个块赶出去。此为scan。

#### 一些解决办法

对于这个问题，其它的一些算法。

2Q算法，想法是引入两个队列，一个队列是FIFO队列，另一个是LRU队列。2Q算法对于第二个问题有不错的解决，再也不会被访问的数据会在FIFO队列中渐渐离开。但对于第一个问题，如果间隔周期还是很大，大于了FIFO队列的长度(而FIFO队列只有cache的几分之一大)，并没有解决。

第二种，LIP,BIP,DIP算法，LIP的想法是，与LRU正好相反，不把新插入的放在LRU，而是放在MRU。这个算法很简单，但是有个非常明显的缺点，cache得不到更新。BIP针对这点做了改进，有小概率会插入到MRU而不是LRU。这样虽然缓慢(由概率决定)，对于(a1,...,aT1)N(b1,...,bT2)N2这样的pattern，N1,N2够大，对于LIP，由于它在插入了K-1个以后不再更新，所以对a部分有一定命中率(容易得到是(K-1)/T1)，但对b部分则完全不会命中，如果后面还有其它，也不会命中。但BIP的更新使得它在稳定之后(迭代次数够多)，对b能达到近似(K-1)/T2的命中率。
但由于对局部性利用不好，大多数的情况BIP的效果都会明显差于LRU。为此又引入了DIP，它的想法就是拨出了dedicated set，比如说，每32个set中选出一个用BIP，一个用LRU，根据LRU和BIP缺失率的表现来决定剩余的set用哪一个。平均来说，它的表现更好。

第三种，SRRIP,BRRIP和DRRIP。这个系列是对LIP,BIP,DIP算法的模仿。最关键的不同，就是引入了共2^M^个值，并且SRRIP初始化。对于SRRIP，hit时为2^M^-2，这使得它不会立即被驱逐出去(取2^M^-1的驱逐出去)。BRRIP也是引入了随机化，有较大概率是2^M^-1，这样更类似LIP，有较小概率是2^M^-2。hit策略上有HP和FP两种，前者是如果hit立即为0，后者上hit会让RRPV-1。类似DIP，DRRIP也用了set dueling的想法。它相比于LIP系列主要不同在于insert的2^M^-2避免了刚进入的立即被驱逐出去。

### LIRS算法

#### 原理

##### 基本概念

关于LIRS有2个重要的概念，Recency和Inter-Reference Recency(简记为IRR)。先来介绍这两个概念。Recency就是从上一次用到这个块到现在，又用了多少个其它的块，注意，不是多少次，而是多少个。比如下面的C，在第4个周期用到了它，到了第10个周期，期间访问了5次，但B是重用过的，因此它的Recency(之后简记为R)为4。IRR则是两次访问间的间隔(仍然是块数)。比如D两次之间(2,7)有C,B,A访问过，是3。如果没有重用，那么就为无穷大。一个常用的cache块应该有着比较小的IRR。反过来，如果一个数据用过一次就不再用了，它的IRR就是无穷。

![image-20200609161053470](/Users/quebec/Library/Application Support/typora-user-images/image-20200609161053470.png)

然后引入这种算法的关键概念，HIR(High Inter- reference Recency)和LIR(Low Inter-reference Recency)，前者就是IRR比较大的，后者是IRR更小的。从前面对IRR的讨论，LIR是更重要的。对cache来说，LIRS的比例比HIR要高得多。LIR数量有限，HIR同样如此。当LIR的数量没有达到限制的时候，都算作LIR。那么什么时候HIR可以变成LIR呢？当一个块的IRR<已有的LIR中的R的最大值的时候。为什么不是对IRR比较，而是对R比较呢？

1. **因为IRR如果有新的块访问是不改变的**。或许一个块只访问了2次，不过它的IRR是0，那么之后它的IRR一直是0。但显然，它不应该一直留在cache中。

2. 如果有块的R比这个HIR块的IRR要大，那么就算下一次它就被访问，根据概念IRR也还是比HIR要大。

##### 算法的想法

现在来介绍算法。引入栈S和队列Q，栈S存的是LIR和部分HIR，Q只存放HIR。引入它们的作用是**避免直接维护R和IRR**。它们起到了对LIR的R和HIR的IRR作比较的作用。S的栈顶是最近的，H的队首是最先离开的(也就是victim)。cache中的块要么是Q中的HIR(也可能在S中)，要么是S中的LIR。

非常重要的一点，**LIR必然在cache中，HIR则只有在队列Q中的才在cache中**。我们用r(residence)来表示已经在cache中。

在算法稳定之后，S和Q的大小是不改变的。而且**S的进出关系保证了：S是按照R的排序的，S的栈顶是最近访问的，S的栈底R最大**。这引出了栈剪枝的概念，也就是如果LIR从栈S中移除出去，此时栈底有可能是HIR，那么把栈底所有的HIR也从S中移除(但有可能在队列Q中，因此可能还在cache中)。为什么要这样？原因就是，在栈底的HIR，意味着它的R>=栈中的任意的LIR的R，那么就算它即将被访问，它的IRR(=R)也不可能<栈中的任意的LIR的R，它没有机会再成为LIR了。不过如果真的它紧接着被访问，它会重新来到栈顶的。

##### 栈剪枝的正确性

栈是按照R排的序，栈顶的R最小，栈底则最大，如果已经有HIR在栈底，这说明它的R是最大的，当然也>=所有的LIRS块，那么即使下一个要访问的就是它，它的IRR也会>=所有LIRS块的R，因此它没有希望变成LIRS了，所以移出栈中。

如果HIR在S中(由于栈剪枝，一定不在栈底，它的R一定<底部LIR的R)，它再次被访问，那么它的IRR就会小于底部LIR的R，根据规则，它会变成LIR，很自然，底部的LIR就会离开，它去了Q的队尾。

因此我们可以看到，引入栈的确与之前IRR与R的比较是等价的。

#### 算法描述

```
命中
    if 在S中
        if 是LIR
            移动到S栈顶，如原在栈底，栈剪枝
        else
            放到S栈顶，变为LIR，从Q中移出，S底部的LIR到Q中的队尾，栈剪枝
    else
        移动到S栈顶，移到Q的队尾

缺失：必是HIR，victim是Q队首
    移出Q的队首
    if 在S中
        放到S栈顶，变为LIR，从Q中移出，S底部的LIR到Q中的队尾，栈剪枝
    else
        放到Q队首，为HIR
```

一旦被访问，无论之前是什么状态，都放到栈顶。很好理解，因为说过栈是按R排序的。

#### 实现上的改进

在实现中，每一个组都有对应的一个LIRS对象，list Q,S是必维护的，其实仅仅要它们就足够了，但这样查找操作复杂度就是O(n)了(虽然要查找的也不会太多，Q大小仅仅为2，S大小最小是30，最大也很难超过100)。于是引入了哈希表，这样查找就是常数级了。考虑到Q,S本来就很小，很难说效率上有什么提高。反而增加了维护Q,S的麻烦。

是常数级的，是O(1)，不过其它的算法效率也不低。

#### 效果的理论考虑

为什么需要IRR和R？重用间隔IRR非常妙，因为它揭示了下一次出现它的概率。R表现的则是一种潜力。

##### thrash

对于thrash，间隔距离长的，举个例子：a1,a2,a3,a4,a5,a6，如此循环，假设cache只有4个块，其中3个是LIR，1个是HIR(实际中HIR的比例比这小得多，典型值是1%)。

对LIR，正确率会是0。我们模拟LIRS，正确率是50%(a1,a2,a3始终能命中，而a4-a6则总是缺失)。事实上对于长于cache容量的那部分都是缺失，LIR容量那部分则总是能命中，设cache容量为S1，LIR容量为S2，pattern一个循环的长度为S3，那么正确率为S2/S3。我们也能看出，LIR的比例越高，对这类问题效果更好。

##### scan

对于scan它也有很好的表现，如果中间一堆数据干扰，此后再不出现，从算法可知，它们永无机会成为LIR，影响的只是HIR，而HIR且residence的比例很小，因此它们的影响也很小。所以对于scan有着优异的表现。

那么是不是H越小越好呢？当然不是。看下面这个讨论。

##### 什么时候表现不佳

一开始的数据(容量>=S的容量)后来再也没有被用过，而后面的数据的循环长度>Q的容量。稳定后命中率是0。这种情况比LRU更糟糕，因为LRU可能循环长度<总cache容量，原因就在于LIR的比例很多(99%)。也就是说，LIRS对一开始的数据是敏感的。而且一开始的scan/S的容量越多，效果越糟糕。这也提示我们，H也不能一味小。



### 实验结果

以下文件分别对应1-6

"fortnite60fps_b620_1.txt"

"fortnite60fps_b620_2.txt"

"hepingjingying60fps_b620_1.txt"

"hepingjingying60fps_b620_2.txt"

"wangzherongyao60fps_b620_1.txt"

"wangzherongyao60fps_b620_2.txt”

| 命中率   | 1              | 2              | 3              | 4              | 5              | 6              |
| -------- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- |
| RAND     | 9.836136%      | 14.014773%     | 14.843126%     | 15.444791%     | 16.272644%     | 17.542135%     |
| LRU      | 9.764601%      | 15.773251%     | 16.059805%     | 16.592953%     | 18.489758%     | 19.989316%     |
| FRU      | 11.137485%     | 11.437043%     | 11.233655%     | 14.252903%     | 16.262376%     | 16.072570%     |
| SRRIP    | 10.544985%     | 15.676582%     | 16.098861%     | **17.296910%** | 18.814370%     | 19.884496%     |
| SRRIP_FP | 10.081127%     | **16.008420%** | **16.212840%** | 17.115863%     | 18.873923%     | **20.203499%** |
| BRRIP    | **14.492665%** | 14.375893%     | 14.692341%     | 15.683447%     | **19.585600%** | 19.083035%     |
| DRRIP    | 10.660773%     | 15.582679%     | 16.009839%     | 17.210150%     | 18.833313%     | 19.842741%     |
| LIRS     | 10.286695%     | 12.303695%     | 14.274304%     | 15.735452%     | 17.072753%     | 17.438116%     |

SRRIP系列包揽了全部的最优。平均最好的是SRRIP_FP。

### 小结

这次cache实验由于拖延和回避心理，一直没解决代码中的问题。是我一学期颓废、拖沓的写照。我对cache的策略有了更多的了解，而且也是第一次比较多地看了论文(虽然一共好像就看了4篇，而且跳过了差不多一半内容)。非常感谢助教和老师。第一次推迟ddl，我心里就想，老师和助教真好呀。我对不起你们。